# Part 4: What AI Gets Wrong
## Topics 9â€“10 | ~20 minutes

---

## Slide 9: Hallucinations â€” When AI Is Confidently Wrong

- AI makes things up regularly, confidently, with perfect grammar
- Demo: Ask about fake case "Robertson v. McKenzie (1987)" â†’ AI invents details
- Real-world: NY lawyer sanctioned for citing AI-generated fake cases
- HIGH risk: specific dates, names, statistics, niche domains
- LOW risk: general knowledge, creative tasks, reformatting your content
- Rule: AI is your first draft, never your final answer

### The 30-Second Verification Rule
1. ğŸ” Google the specific claim
2. ğŸ”„ Ask a second AI the same question
3. â“ Ask the AI: "Are you sure? Source?"
4. ğŸ“‹ For anything important: verify with a real source

---

## Slide 10: Privacy & Data

| Service | Trains on Your Data? | Notes |
|---------|---------------------|-------|
| ChatGPT (free) | Yes by default | Opt out in Data Controls |
| ChatGPT Plus | Yes by default | Toggle off in settings |
| Claude.ai | No (by default) | Anthropic doesn't train on conversations |
| Gemini | Yes | Tied to Google account |
| API (OpenClaw) | No | Paying customers â‰  training data |

### Rules of Thumb
- âœ… SAFE: Public info, creative writing, general questions
- âš ï¸ THINK TWICE: Client details, strategies, financial info, NDAs
- âŒ NEVER: Passwords, credit cards, SIN numbers, medical records with names
- Bottom line: treat AI like a smart coworker you don't fully trust yet
